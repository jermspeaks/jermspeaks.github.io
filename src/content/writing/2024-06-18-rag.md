---
description: An explainer for Retrieval-Augmented Generation (RAG). Breaking down what it is and how people are implementing it.
draft: false
pubDate: "2024-06-18T23:00:00.000Z"
tags: ["learning", "ai"]
title: Retrieval-Augmented Generation (RAG)
heroImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1713375387925/9246942a-79e4-4d94-b032-a85f10480a99.png
heroImageAlt: Diagram of one implementation of RAG from LangChain
---

RAG is a framework that aids LLMs to retrieve other datasets to augment the prompt and your generate a response based off the added data source.

Breaking down the acrynpm, RAG means the following:

- **R**etrieval mechanism: turn your query into a vector and run a vector search from a database that has pre-encoded documents and passages
- **A**ugmentation: Combine retrieved documents with the initial prompt to create an augmented prompt
- Answer **G**eneration: With the new prompt, the LLM will generate a response informed by the external knowledge contained in the retrieved texts

It started with this paper: [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401?ref=cohere-ai.ghost.io).

This method is particularly valuable in fields like chatbot development, where the ability to provide precise answers derived from extensive databases of knowledge is crucial.

RAG fundamentally enhances the natural language understanding and generation capabilities of models by allowing them to access and leverage a vast amount of external knowledge. The approach is built upon the synergy between two main components: a retrieval system and a generative model. The retrieval system first identifies relevant information from a knowledge base, which the generative model then uses to craft responses that are not only accurate but also rich in detail and scope.

### Types of RAG

1. Vector-based RAG - the most common type of RAG.

You convert text into "embeddings" and store them in a vector database.

![Overview showing RAG with a Vector DB](https://writer.com/wp-content/uploads/2024/02/Image-1.png)

> Vector databases enable search functions that are much better than typical keyword searches. If users are looking for data that has semantic similarity, a vector database can often help them find those data points, even if there isnâ€™t a literal keyword match
>
> -- Deanna Dong, [Vector databases, graph databases, and knowledge graphs - Writer](https://writer.com/blog/vector-databases-graph-databases-knowledge-graphs/)

The downside is the context can be lost, especially when its relational context between data points. When chunking vectors, they use data-point similarity based on nearness. See KNN (k-nearest neighbors) and ANN (Approximate Nearest Neighbor)

2. Graph-based RAG

Instead of using a vector database, you use a Graph Database. A Graph DB contains vector information where links also store data. This allows relational information from retrieval

![Example showing relationships in a Graph DB](https://writer.com/wp-content/uploads/2024/02/Image-2.png)

Sam Julien on X Thread - [Whatâ€™s graph-based RAG (retrieval-augmented generation) and why should you care?](https://twitter.com/samjulien/status/1801634334723432462)

![Using RAG with a Graph DB](https://pbs.twimg.com/media/GQCw4OHXwAA0_uR?format=jpg&name=large)

3. Knowledge graphs

These outperform vector and graph databases due to their ability to preserve semantic relationships and encode structural information

### Relevant sources for follow-up

- [Five Reasons Enterprises Are Choosing RAG](https://cohere.com/blog/five-reasons-enterprises-are-choosing-rag)
- LangChain Github for [RAG from Scratch](https://github.com/langchain-ai/rag-from-scratch)
- Akshay ðŸš€ on X thread - [RAGs, clearly explained](https://twitter.com/akshay_pachaar/status/1791446077696266334)

<iframe
  class="aspect-video w-full my-2"
  src="https://www.youtube.com/embed/T-D1OfcDW1M"
  title="What is Retrieval-Augmented Generation (RAG)?"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
  allowfullscreen></iframe>

<iframe
  class="aspect-video w-full my-2"
  src="https://www.youtube.com/embed/rhZgXNdhWDY"
  title="Retrieval Augmented Generation (RAG) Explained: Embedding, Sentence BERT, Vector Database (HNSW)"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
  allowfullscreen></iframe>
